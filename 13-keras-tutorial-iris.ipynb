{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv파일 read lib\n",
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv('./dataset/iris/iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas lib에 의해 생성된 데이터의 정보를 표현\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "['Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica']\n"
     ]
    }
   ],
   "source": [
    "# iloc함수는 data를 pandas dataframe 형태로 반환\n",
    "# ix함수는 인덱스 순서를 지키지 않으므로 주의 => 데이터의 순서를 중시\n",
    "# dataframe.values는 numpy.ndarray 형태로 반환\n",
    "X = dataset.iloc[:,1:-1].values\n",
    "y = dataset.iloc[:,-1].values\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# sklearn은 ML라이브러리 이다. 지금은 keras를 사용하여 deep learning을 하기 때문에\n",
    "# 머신러닝을 하지 않지만, 데이터 전처리를 하기위해 sklearn을 사용\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# LabelEncoder클래스 할당\n",
    "label_encoder_y = LabelEncoder()\n",
    "# 기존의 데이터 y 꽃이름별로 3가지 클래스를 => 0 , 1 , 2 로 변환\n",
    "y = label_encoder_y.fit_transform(y)\n",
    "print(y)\n",
    "# One-Hot Encoding 1 ,0 ,0 => 0, :: 0, 1, 0 => 1 :: 0, 0, 1 => 2 로 변환\n",
    "y = to_categorical(y)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-9.00681170e-01  1.03205722e+00 -1.34127240e+00 -1.31297673e+00]\n",
      " [-1.14301691e+00 -1.24957601e-01 -1.34127240e+00 -1.31297673e+00]\n",
      " [-1.38535265e+00  3.37848329e-01 -1.39813811e+00 -1.31297673e+00]\n",
      " [-1.50652052e+00  1.06445364e-01 -1.28440670e+00 -1.31297673e+00]\n",
      " [-1.02184904e+00  1.26346019e+00 -1.34127240e+00 -1.31297673e+00]\n",
      " [-5.37177559e-01  1.95766909e+00 -1.17067529e+00 -1.05003079e+00]\n",
      " [-1.50652052e+00  8.00654259e-01 -1.34127240e+00 -1.18150376e+00]\n",
      " [-1.02184904e+00  8.00654259e-01 -1.28440670e+00 -1.31297673e+00]\n",
      " [-1.74885626e+00 -3.56360566e-01 -1.34127240e+00 -1.31297673e+00]\n",
      " [-1.14301691e+00  1.06445364e-01 -1.28440670e+00 -1.44444970e+00]\n",
      " [-5.37177559e-01  1.49486315e+00 -1.28440670e+00 -1.31297673e+00]\n",
      " [-1.26418478e+00  8.00654259e-01 -1.22754100e+00 -1.31297673e+00]\n",
      " [-1.26418478e+00 -1.24957601e-01 -1.34127240e+00 -1.44444970e+00]\n",
      " [-1.87002413e+00 -1.24957601e-01 -1.51186952e+00 -1.44444970e+00]\n",
      " [-5.25060772e-02  2.18907205e+00 -1.45500381e+00 -1.31297673e+00]\n",
      " [-1.73673948e-01  3.11468391e+00 -1.28440670e+00 -1.05003079e+00]\n",
      " [-5.37177559e-01  1.95766909e+00 -1.39813811e+00 -1.05003079e+00]\n",
      " [-9.00681170e-01  1.03205722e+00 -1.34127240e+00 -1.18150376e+00]\n",
      " [-1.73673948e-01  1.72626612e+00 -1.17067529e+00 -1.18150376e+00]\n",
      " [-9.00681170e-01  1.72626612e+00 -1.28440670e+00 -1.18150376e+00]\n",
      " [-5.37177559e-01  8.00654259e-01 -1.17067529e+00 -1.31297673e+00]\n",
      " [-9.00681170e-01  1.49486315e+00 -1.28440670e+00 -1.05003079e+00]\n",
      " [-1.50652052e+00  1.26346019e+00 -1.56873522e+00 -1.31297673e+00]\n",
      " [-9.00681170e-01  5.69251294e-01 -1.17067529e+00 -9.18557817e-01]\n",
      " [-1.26418478e+00  8.00654259e-01 -1.05694388e+00 -1.31297673e+00]\n",
      " [-1.02184904e+00 -1.24957601e-01 -1.22754100e+00 -1.31297673e+00]\n",
      " [-1.02184904e+00  8.00654259e-01 -1.22754100e+00 -1.05003079e+00]\n",
      " [-7.79513300e-01  1.03205722e+00 -1.28440670e+00 -1.31297673e+00]\n",
      " [-7.79513300e-01  8.00654259e-01 -1.34127240e+00 -1.31297673e+00]\n",
      " [-1.38535265e+00  3.37848329e-01 -1.22754100e+00 -1.31297673e+00]\n",
      " [-1.26418478e+00  1.06445364e-01 -1.22754100e+00 -1.31297673e+00]\n",
      " [-5.37177559e-01  8.00654259e-01 -1.28440670e+00 -1.05003079e+00]\n",
      " [-7.79513300e-01  2.42047502e+00 -1.28440670e+00 -1.44444970e+00]\n",
      " [-4.16009689e-01  2.65187798e+00 -1.34127240e+00 -1.31297673e+00]\n",
      " [-1.14301691e+00  1.06445364e-01 -1.28440670e+00 -1.44444970e+00]\n",
      " [-1.02184904e+00  3.37848329e-01 -1.45500381e+00 -1.31297673e+00]\n",
      " [-4.16009689e-01  1.03205722e+00 -1.39813811e+00 -1.31297673e+00]\n",
      " [-1.14301691e+00  1.06445364e-01 -1.28440670e+00 -1.44444970e+00]\n",
      " [-1.74885626e+00 -1.24957601e-01 -1.39813811e+00 -1.31297673e+00]\n",
      " [-9.00681170e-01  8.00654259e-01 -1.28440670e+00 -1.31297673e+00]\n",
      " [-1.02184904e+00  1.03205722e+00 -1.39813811e+00 -1.18150376e+00]\n",
      " [-1.62768839e+00 -1.74477836e+00 -1.39813811e+00 -1.18150376e+00]\n",
      " [-1.74885626e+00  3.37848329e-01 -1.39813811e+00 -1.31297673e+00]\n",
      " [-1.02184904e+00  1.03205722e+00 -1.22754100e+00 -7.87084847e-01]\n",
      " [-9.00681170e-01  1.72626612e+00 -1.05694388e+00 -1.05003079e+00]\n",
      " [-1.26418478e+00 -1.24957601e-01 -1.34127240e+00 -1.18150376e+00]\n",
      " [-9.00681170e-01  1.72626612e+00 -1.22754100e+00 -1.31297673e+00]\n",
      " [-1.50652052e+00  3.37848329e-01 -1.34127240e+00 -1.31297673e+00]\n",
      " [-6.58345429e-01  1.49486315e+00 -1.28440670e+00 -1.31297673e+00]\n",
      " [-1.02184904e+00  5.69251294e-01 -1.34127240e+00 -1.31297673e+00]\n",
      " [ 1.40150837e+00  3.37848329e-01  5.35295827e-01  2.64698913e-01]\n",
      " [ 6.74501145e-01  3.37848329e-01  4.21564419e-01  3.96171883e-01]\n",
      " [ 1.28034050e+00  1.06445364e-01  6.49027235e-01  3.96171883e-01]\n",
      " [-4.16009689e-01 -1.74477836e+00  1.37235899e-01  1.33225943e-01]\n",
      " [ 7.95669016e-01 -5.87763531e-01  4.78430123e-01  3.96171883e-01]\n",
      " [-1.73673948e-01 -5.87763531e-01  4.21564419e-01  1.33225943e-01]\n",
      " [ 5.53333275e-01  5.69251294e-01  5.35295827e-01  5.27644853e-01]\n",
      " [-1.14301691e+00 -1.51337539e+00 -2.60824029e-01 -2.61192967e-01]\n",
      " [ 9.16836886e-01 -3.56360566e-01  4.78430123e-01  1.33225943e-01]\n",
      " [-7.79513300e-01 -8.19166497e-01  8.03701950e-02  2.64698913e-01]\n",
      " [-1.02184904e+00 -2.43898725e+00 -1.47092621e-01 -2.61192967e-01]\n",
      " [ 6.86617933e-02 -1.24957601e-01  2.50967307e-01  3.96171883e-01]\n",
      " [ 1.89829664e-01 -1.97618132e+00  1.37235899e-01 -2.61192967e-01]\n",
      " [ 3.10997534e-01 -3.56360566e-01  5.35295827e-01  2.64698913e-01]\n",
      " [-2.94841818e-01 -3.56360566e-01 -9.02269170e-02  1.33225943e-01]\n",
      " [ 1.03800476e+00  1.06445364e-01  3.64698715e-01  2.64698913e-01]\n",
      " [-2.94841818e-01 -1.24957601e-01  4.21564419e-01  3.96171883e-01]\n",
      " [-5.25060772e-02 -8.19166497e-01  1.94101603e-01 -2.61192967e-01]\n",
      " [ 4.32165405e-01 -1.97618132e+00  4.21564419e-01  3.96171883e-01]\n",
      " [-2.94841818e-01 -1.28197243e+00  8.03701950e-02 -1.29719997e-01]\n",
      " [ 6.86617933e-02  3.37848329e-01  5.92161531e-01  7.90590793e-01]\n",
      " [ 3.10997534e-01 -5.87763531e-01  1.37235899e-01  1.33225943e-01]\n",
      " [ 5.53333275e-01 -1.28197243e+00  6.49027235e-01  3.96171883e-01]\n",
      " [ 3.10997534e-01 -5.87763531e-01  5.35295827e-01  1.75297293e-03]\n",
      " [ 6.74501145e-01 -3.56360566e-01  3.07833011e-01  1.33225943e-01]\n",
      " [ 9.16836886e-01 -1.24957601e-01  3.64698715e-01  2.64698913e-01]\n",
      " [ 1.15917263e+00 -5.87763531e-01  5.92161531e-01  2.64698913e-01]\n",
      " [ 1.03800476e+00 -1.24957601e-01  7.05892939e-01  6.59117823e-01]\n",
      " [ 1.89829664e-01 -3.56360566e-01  4.21564419e-01  3.96171883e-01]\n",
      " [-1.73673948e-01 -1.05056946e+00 -1.47092621e-01 -2.61192967e-01]\n",
      " [-4.16009689e-01 -1.51337539e+00  2.35044910e-02 -1.29719997e-01]\n",
      " [-4.16009689e-01 -1.51337539e+00 -3.33612130e-02 -2.61192967e-01]\n",
      " [-5.25060772e-02 -8.19166497e-01  8.03701950e-02  1.75297293e-03]\n",
      " [ 1.89829664e-01 -8.19166497e-01  7.62758643e-01  5.27644853e-01]\n",
      " [-5.37177559e-01 -1.24957601e-01  4.21564419e-01  3.96171883e-01]\n",
      " [ 1.89829664e-01  8.00654259e-01  4.21564419e-01  5.27644853e-01]\n",
      " [ 1.03800476e+00  1.06445364e-01  5.35295827e-01  3.96171883e-01]\n",
      " [ 5.53333275e-01 -1.74477836e+00  3.64698715e-01  1.33225943e-01]\n",
      " [-2.94841818e-01 -1.24957601e-01  1.94101603e-01  1.33225943e-01]\n",
      " [-4.16009689e-01 -1.28197243e+00  1.37235899e-01  1.33225943e-01]\n",
      " [-4.16009689e-01 -1.05056946e+00  3.64698715e-01  1.75297293e-03]\n",
      " [ 3.10997534e-01 -1.24957601e-01  4.78430123e-01  2.64698913e-01]\n",
      " [-5.25060772e-02 -1.05056946e+00  1.37235899e-01  1.75297293e-03]\n",
      " [-1.02184904e+00 -1.74477836e+00 -2.60824029e-01 -2.61192967e-01]\n",
      " [-2.94841818e-01 -8.19166497e-01  2.50967307e-01  1.33225943e-01]\n",
      " [-1.73673948e-01 -1.24957601e-01  2.50967307e-01  1.75297293e-03]\n",
      " [-1.73673948e-01 -3.56360566e-01  2.50967307e-01  1.33225943e-01]\n",
      " [ 4.32165405e-01 -3.56360566e-01  3.07833011e-01  1.33225943e-01]\n",
      " [-9.00681170e-01 -1.28197243e+00 -4.31421141e-01 -1.29719997e-01]\n",
      " [-1.73673948e-01 -5.87763531e-01  1.94101603e-01  1.33225943e-01]\n",
      " [ 5.53333275e-01  5.69251294e-01  1.27454998e+00  1.71090158e+00]\n",
      " [-5.25060772e-02 -8.19166497e-01  7.62758643e-01  9.22063763e-01]\n",
      " [ 1.52267624e+00 -1.24957601e-01  1.21768427e+00  1.18500970e+00]\n",
      " [ 5.53333275e-01 -3.56360566e-01  1.04708716e+00  7.90590793e-01]\n",
      " [ 7.95669016e-01 -1.24957601e-01  1.16081857e+00  1.31648267e+00]\n",
      " [ 2.12851559e+00 -1.24957601e-01  1.61574420e+00  1.18500970e+00]\n",
      " [-1.14301691e+00 -1.28197243e+00  4.21564419e-01  6.59117823e-01]\n",
      " [ 1.76501198e+00 -3.56360566e-01  1.44514709e+00  7.90590793e-01]\n",
      " [ 1.03800476e+00 -1.28197243e+00  1.16081857e+00  7.90590793e-01]\n",
      " [ 1.64384411e+00  1.26346019e+00  1.33141568e+00  1.71090158e+00]\n",
      " [ 7.95669016e-01  3.37848329e-01  7.62758643e-01  1.05353673e+00]\n",
      " [ 6.74501145e-01 -8.19166497e-01  8.76490051e-01  9.22063763e-01]\n",
      " [ 1.15917263e+00 -1.24957601e-01  9.90221459e-01  1.18500970e+00]\n",
      " [-1.73673948e-01 -1.28197243e+00  7.05892939e-01  1.05353673e+00]\n",
      " [-5.25060772e-02 -5.87763531e-01  7.62758643e-01  1.57942861e+00]\n",
      " [ 6.74501145e-01  3.37848329e-01  8.76490051e-01  1.44795564e+00]\n",
      " [ 7.95669016e-01 -1.24957601e-01  9.90221459e-01  7.90590793e-01]\n",
      " [ 2.24968346e+00  1.72626612e+00  1.67260991e+00  1.31648267e+00]\n",
      " [ 2.24968346e+00 -1.05056946e+00  1.78634131e+00  1.44795564e+00]\n",
      " [ 1.89829664e-01 -1.97618132e+00  7.05892939e-01  3.96171883e-01]\n",
      " [ 1.28034050e+00  3.37848329e-01  1.10395287e+00  1.44795564e+00]\n",
      " [-2.94841818e-01 -5.87763531e-01  6.49027235e-01  1.05353673e+00]\n",
      " [ 2.24968346e+00 -5.87763531e-01  1.67260991e+00  1.05353673e+00]\n",
      " [ 5.53333275e-01 -8.19166497e-01  6.49027235e-01  7.90590793e-01]\n",
      " [ 1.03800476e+00  5.69251294e-01  1.10395287e+00  1.18500970e+00]\n",
      " [ 1.64384411e+00  3.37848329e-01  1.27454998e+00  7.90590793e-01]\n",
      " [ 4.32165405e-01 -5.87763531e-01  5.92161531e-01  7.90590793e-01]\n",
      " [ 3.10997534e-01 -1.24957601e-01  6.49027235e-01  7.90590793e-01]\n",
      " [ 6.74501145e-01 -5.87763531e-01  1.04708716e+00  1.18500970e+00]\n",
      " [ 1.64384411e+00 -1.24957601e-01  1.16081857e+00  5.27644853e-01]\n",
      " [ 1.88617985e+00 -5.87763531e-01  1.33141568e+00  9.22063763e-01]\n",
      " [ 2.49201920e+00  1.72626612e+00  1.50201279e+00  1.05353673e+00]\n",
      " [ 6.74501145e-01 -5.87763531e-01  1.04708716e+00  1.31648267e+00]\n",
      " [ 5.53333275e-01 -5.87763531e-01  7.62758643e-01  3.96171883e-01]\n",
      " [ 3.10997534e-01 -1.05056946e+00  1.04708716e+00  2.64698913e-01]\n",
      " [ 2.24968346e+00 -1.24957601e-01  1.33141568e+00  1.44795564e+00]\n",
      " [ 5.53333275e-01  8.00654259e-01  1.04708716e+00  1.57942861e+00]\n",
      " [ 6.74501145e-01  1.06445364e-01  9.90221459e-01  7.90590793e-01]\n",
      " [ 1.89829664e-01 -1.24957601e-01  5.92161531e-01  7.90590793e-01]\n",
      " [ 1.28034050e+00  1.06445364e-01  9.33355755e-01  1.18500970e+00]\n",
      " [ 1.03800476e+00  1.06445364e-01  1.04708716e+00  1.57942861e+00]\n",
      " [ 1.28034050e+00  1.06445364e-01  7.62758643e-01  1.44795564e+00]\n",
      " [-5.25060772e-02 -8.19166497e-01  7.62758643e-01  9.22063763e-01]\n",
      " [ 1.15917263e+00  3.37848329e-01  1.21768427e+00  1.44795564e+00]\n",
      " [ 1.03800476e+00  5.69251294e-01  1.10395287e+00  1.71090158e+00]\n",
      " [ 1.03800476e+00 -1.24957601e-01  8.19624347e-01  1.44795564e+00]\n",
      " [ 5.53333275e-01 -1.28197243e+00  7.05892939e-01  9.22063763e-01]\n",
      " [ 7.95669016e-01 -1.24957601e-01  8.19624347e-01  1.05353673e+00]\n",
      " [ 4.32165405e-01  8.00654259e-01  9.33355755e-01  1.44795564e+00]\n",
      " [ 6.86617933e-02 -1.24957601e-01  7.62758643e-01  7.90590793e-01]]\n"
     ]
    }
   ],
   "source": [
    "# 스케일링은 자료 집합에 적용되는 전처리 과정으로 모든 자료에 선형 변환을 적용하여 전체 자료의 분포를 평균 0, 분산 1이 되도록 만드는 과정이다.스케일링은 자료의 오버플로우(overflow)나 언더플로우(underflow)를 방지하고 독립 변수의 공분산 행렬의 조건수(condition number)를 감소시켜 최적화 과정에서의 안정성 및 수렴 속도를 향상시킨다.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "X = standard_scaler.fit_transform(X)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split함수는 train,test로 데이터를 바꿔준다.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_23 (Dense)             (None, 32)                160       \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 259\n",
      "Trainable params: 259\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 설계 코드\n",
    "# 케라스에서는 딥러닝 전체모델을 Sequential에 올리도록한다.\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "# Sequential클래스 할당\n",
    "model = Sequential()\n",
    "\n",
    "# 첫번째 계층 32개의 뉴런 입력 4개 활성화 함수는 시그모이드\n",
    "model.add(Dense(32, input_dim = 4, activation = 'sigmoid'))\n",
    "# 두번째 계층 출력 계층 3개의 뉴런, 입력 == 32 , 활성화 함수는 소프트맥스\n",
    "model.add(Dense(3, activation = 'softmax'))\n",
    "# 최적화 함수는 == adam , 손실함수는 categorical crossentropy, 평가척도  매트릭스를 할당하지 않을시 각 모델의 학습결과로 평가척도를 제공하지않음\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(Dense(32, input_dim = 4, activation = 'sigmoid'))\n",
    "# model.add(Dense(64, activation = 'sigmoid'))\n",
    "# model.add(Dense(128, activation = 'sigmoid'))\n",
    "# model.add(Dense(3, activation = 'softmax'))\n",
    "# model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 0s - loss: 1.2475 - acc: 0.3167\n",
      "Epoch 2/50\n",
      " - 0s - loss: 1.2252 - acc: 0.3167\n",
      "Epoch 3/50\n",
      " - 0s - loss: 1.2032 - acc: 0.3167\n",
      "Epoch 4/50\n",
      " - 0s - loss: 1.1822 - acc: 0.3167\n",
      "Epoch 5/50\n",
      " - 0s - loss: 1.1625 - acc: 0.3167\n",
      "Epoch 6/50\n",
      " - 0s - loss: 1.1419 - acc: 0.3250\n",
      "Epoch 7/50\n",
      " - 0s - loss: 1.1235 - acc: 0.3333\n",
      "Epoch 8/50\n",
      " - 0s - loss: 1.1059 - acc: 0.3667\n",
      "Epoch 9/50\n",
      " - 0s - loss: 1.0891 - acc: 0.3917\n",
      "Epoch 10/50\n",
      " - 0s - loss: 1.0746 - acc: 0.4333\n",
      "Epoch 11/50\n",
      " - 0s - loss: 1.0606 - acc: 0.4833\n",
      "Epoch 12/50\n",
      " - 0s - loss: 1.0467 - acc: 0.5417\n",
      "Epoch 13/50\n",
      " - 0s - loss: 1.0341 - acc: 0.5583\n",
      "Epoch 14/50\n",
      " - 0s - loss: 1.0216 - acc: 0.6167\n",
      "Epoch 15/50\n",
      " - 0s - loss: 1.0096 - acc: 0.6583\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.9999 - acc: 0.6667\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.9881 - acc: 0.6667\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.9790 - acc: 0.6667\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.9697 - acc: 0.6583\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.9616 - acc: 0.6583\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.9522 - acc: 0.6500\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.9435 - acc: 0.6500\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.9356 - acc: 0.6583\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.9275 - acc: 0.7250\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.9199 - acc: 0.7917\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.9122 - acc: 0.8000\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.9045 - acc: 0.8167\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.8970 - acc: 0.8083\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.8896 - acc: 0.8083\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.8826 - acc: 0.8000\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.8757 - acc: 0.8083\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.8684 - acc: 0.7917\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.8614 - acc: 0.7917\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.8546 - acc: 0.8000\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.8479 - acc: 0.8000\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.8412 - acc: 0.8000\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.8345 - acc: 0.8000\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.8282 - acc: 0.8000\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.8215 - acc: 0.8083\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.8152 - acc: 0.8083\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.8088 - acc: 0.8083\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.8028 - acc: 0.8083\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.7964 - acc: 0.8083\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.7904 - acc: 0.8083\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.7844 - acc: 0.8083\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.7784 - acc: 0.8250\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.7725 - acc: 0.8333\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.7666 - acc: 0.8333\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.7610 - acc: 0.8333\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.7553 - acc: 0.8333\n"
     ]
    }
   ],
   "source": [
    "# fit함수는 해달 모델로 학습을 시작하는 것 X축 데이터 == 속성, y축 데이터 == 클래스\n",
    "# 배치사이즈는 한번에 얼만큼의 학습량을 할지를 결정\n",
    "# 한번에 하나씩 학습한다면 효율 올라가지만 성능 내려감\n",
    "# epochs는 250개의 데이터를 얼마만큼 반복하냐 입니다. 50*250\n",
    "# verbose는 0은 조용히 1은 모양으로 2는 글자로\n",
    "hist=model.fit(X_train, y_train, batch_size = 64, epochs = 50, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "30/30 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8257468938827515, 0.8333333134651184]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습된 모델을 테스트 데이터를 이용하여 검증\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 0s - loss: 0.7496 - acc: 0.8333\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.7441 - acc: 0.8417\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.7386 - acc: 0.8417\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.7332 - acc: 0.8417\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.7279 - acc: 0.8417\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.7226 - acc: 0.8417\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.7173 - acc: 0.8417\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.7121 - acc: 0.8333\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.7069 - acc: 0.8333\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.7020 - acc: 0.8333\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.6969 - acc: 0.8333\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.6921 - acc: 0.8333\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.6872 - acc: 0.8333\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.6824 - acc: 0.8417\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.6775 - acc: 0.8417\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.6728 - acc: 0.8417\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.6683 - acc: 0.8417\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.6637 - acc: 0.8417\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.6591 - acc: 0.8417\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.6546 - acc: 0.8500\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.6502 - acc: 0.8500\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.6459 - acc: 0.8500\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.6416 - acc: 0.8500\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.6374 - acc: 0.8500\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.6332 - acc: 0.8500\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.6290 - acc: 0.8500\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.6249 - acc: 0.8500\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.6209 - acc: 0.8500\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.6169 - acc: 0.8417\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.6130 - acc: 0.8417\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.6091 - acc: 0.8417\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.6053 - acc: 0.8417\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.6015 - acc: 0.8417\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.5978 - acc: 0.8417\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.5941 - acc: 0.8417\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.5904 - acc: 0.8417\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.5869 - acc: 0.8417\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.5834 - acc: 0.8417\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.5799 - acc: 0.8417\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.5764 - acc: 0.8417\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.5730 - acc: 0.8417\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.5697 - acc: 0.8500\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.5663 - acc: 0.8500\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.5631 - acc: 0.8500\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.5599 - acc: 0.8500\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.5567 - acc: 0.8500\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.5536 - acc: 0.8500\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.5504 - acc: 0.8500\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.5474 - acc: 0.8500\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.5443 - acc: 0.8500\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.5413 - acc: 0.8500\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.5384 - acc: 0.8500\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.5355 - acc: 0.8500\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.5327 - acc: 0.8500\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.5298 - acc: 0.8500\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.5270 - acc: 0.8500\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.5242 - acc: 0.8583\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.5215 - acc: 0.8583\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.5189 - acc: 0.8583\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.5162 - acc: 0.8583\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.5135 - acc: 0.8583\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.5110 - acc: 0.8667\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.5083 - acc: 0.8667\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.5059 - acc: 0.8750\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.5034 - acc: 0.8750\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.5009 - acc: 0.8833\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.4984 - acc: 0.8833\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.4960 - acc: 0.8833\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.4936 - acc: 0.8833\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.4914 - acc: 0.8833\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.4890 - acc: 0.8833\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.4867 - acc: 0.8833\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.4844 - acc: 0.8833\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.4822 - acc: 0.8833\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.4800 - acc: 0.8833\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.4779 - acc: 0.8833\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.4757 - acc: 0.8833\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.4735 - acc: 0.8833\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.4714 - acc: 0.8833\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.4693 - acc: 0.8833\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.4675 - acc: 0.8833\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.4653 - acc: 0.8917\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.4632 - acc: 0.8917\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.4612 - acc: 0.8917\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.4593 - acc: 0.8917\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.4574 - acc: 0.8917\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.4556 - acc: 0.8917\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.4536 - acc: 0.8917\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.4517 - acc: 0.8833\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.4498 - acc: 0.8917\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.4480 - acc: 0.8917\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.4461 - acc: 0.8917\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.4443 - acc: 0.8917\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.4426 - acc: 0.8917\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.4409 - acc: 0.8917\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.4391 - acc: 0.8917\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.4374 - acc: 0.8917\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.4357 - acc: 0.8917\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.4342 - acc: 0.8917\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.4324 - acc: 0.8917\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit(X_train, y_train, batch_size = 64, epochs = 100, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "30/30 [==============================] - 0s 41us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5005055665969849, 0.8666666746139526]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5. 학습과정 살펴보기\n",
    "# matplotlib는 그래프를 그리는 툴\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# subplots으로 plt차트 한묶음을 생성함\n",
    "# fig은 차트모양에 해당하고\n",
    "# loss_ax 는 손실 차트에 해당함\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "# loss_ax 와 x축을 공유하는 쌍 차트를 생성\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "# loss 차트의 데이터는 loss 색은 yellow 이름은 train loss\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "\n",
    "# ylim을 통해 차트의 최대 최소를 설정가능\n",
    "loss_ax.set_ylim([0.0, 0.5])\n",
    "\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "\n",
    "acc_ax.set_ylim([0.8, 1.0])\n",
    "\n",
    "# loss_ax와 acc_ax는 하나의 epoch축을 끼고 차트를 그림\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "# 범례를 설정하기 위한값\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
