{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv파일 read lib\n",
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv('./dataset/iris/iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas lib에 의해 생성된 데이터의 정보를 표현\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "['Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica']\n"
     ]
    }
   ],
   "source": [
    "# iloc함수는 data를 pandas dataframe 형태로 반환\n",
    "# ix함수는 인덱스 순서를 지키지 않으므로 주의 => 데이터의 순서를 중시\n",
    "# dataframe.values는 numpy.ndarray 형태로 반환\n",
    "X = dataset.iloc[:,1:-1].values\n",
    "y = dataset.iloc[:,-1].values\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# sklearn은 ML라이브러리 이다. 지금은 keras를 사용하여 deep learning을 하기 때문에\n",
    "# 머신러닝을 하지 않지만, 데이터 전처리를 하기위해 sklearn을 사용\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# LabelEncoder클래스 할당\n",
    "label_encoder_y = LabelEncoder()\n",
    "# 기존의 데이터 y 꽃이름별로 3가지 클래스를 => 0 , 1 , 2 로 변환\n",
    "y = label_encoder_y.fit_transform(y)\n",
    "print(y)\n",
    "# One-Hot Encoding 1 ,0 ,0 => 0, :: 0, 1, 0 => 1 :: 0, 0, 1 => 2 로 변환\n",
    "y = to_categorical(y)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-9.00681170e-01  1.03205722e+00 -1.34127240e+00 -1.31297673e+00]\n",
      " [-1.14301691e+00 -1.24957601e-01 -1.34127240e+00 -1.31297673e+00]\n",
      " [-1.38535265e+00  3.37848329e-01 -1.39813811e+00 -1.31297673e+00]\n",
      " [-1.50652052e+00  1.06445364e-01 -1.28440670e+00 -1.31297673e+00]\n",
      " [-1.02184904e+00  1.26346019e+00 -1.34127240e+00 -1.31297673e+00]\n",
      " [-5.37177559e-01  1.95766909e+00 -1.17067529e+00 -1.05003079e+00]\n",
      " [-1.50652052e+00  8.00654259e-01 -1.34127240e+00 -1.18150376e+00]\n",
      " [-1.02184904e+00  8.00654259e-01 -1.28440670e+00 -1.31297673e+00]\n",
      " [-1.74885626e+00 -3.56360566e-01 -1.34127240e+00 -1.31297673e+00]\n",
      " [-1.14301691e+00  1.06445364e-01 -1.28440670e+00 -1.44444970e+00]\n",
      " [-5.37177559e-01  1.49486315e+00 -1.28440670e+00 -1.31297673e+00]\n",
      " [-1.26418478e+00  8.00654259e-01 -1.22754100e+00 -1.31297673e+00]\n",
      " [-1.26418478e+00 -1.24957601e-01 -1.34127240e+00 -1.44444970e+00]\n",
      " [-1.87002413e+00 -1.24957601e-01 -1.51186952e+00 -1.44444970e+00]\n",
      " [-5.25060772e-02  2.18907205e+00 -1.45500381e+00 -1.31297673e+00]\n",
      " [-1.73673948e-01  3.11468391e+00 -1.28440670e+00 -1.05003079e+00]\n",
      " [-5.37177559e-01  1.95766909e+00 -1.39813811e+00 -1.05003079e+00]\n",
      " [-9.00681170e-01  1.03205722e+00 -1.34127240e+00 -1.18150376e+00]\n",
      " [-1.73673948e-01  1.72626612e+00 -1.17067529e+00 -1.18150376e+00]\n",
      " [-9.00681170e-01  1.72626612e+00 -1.28440670e+00 -1.18150376e+00]\n",
      " [-5.37177559e-01  8.00654259e-01 -1.17067529e+00 -1.31297673e+00]\n",
      " [-9.00681170e-01  1.49486315e+00 -1.28440670e+00 -1.05003079e+00]\n",
      " [-1.50652052e+00  1.26346019e+00 -1.56873522e+00 -1.31297673e+00]\n",
      " [-9.00681170e-01  5.69251294e-01 -1.17067529e+00 -9.18557817e-01]\n",
      " [-1.26418478e+00  8.00654259e-01 -1.05694388e+00 -1.31297673e+00]\n",
      " [-1.02184904e+00 -1.24957601e-01 -1.22754100e+00 -1.31297673e+00]\n",
      " [-1.02184904e+00  8.00654259e-01 -1.22754100e+00 -1.05003079e+00]\n",
      " [-7.79513300e-01  1.03205722e+00 -1.28440670e+00 -1.31297673e+00]\n",
      " [-7.79513300e-01  8.00654259e-01 -1.34127240e+00 -1.31297673e+00]\n",
      " [-1.38535265e+00  3.37848329e-01 -1.22754100e+00 -1.31297673e+00]\n",
      " [-1.26418478e+00  1.06445364e-01 -1.22754100e+00 -1.31297673e+00]\n",
      " [-5.37177559e-01  8.00654259e-01 -1.28440670e+00 -1.05003079e+00]\n",
      " [-7.79513300e-01  2.42047502e+00 -1.28440670e+00 -1.44444970e+00]\n",
      " [-4.16009689e-01  2.65187798e+00 -1.34127240e+00 -1.31297673e+00]\n",
      " [-1.14301691e+00  1.06445364e-01 -1.28440670e+00 -1.44444970e+00]\n",
      " [-1.02184904e+00  3.37848329e-01 -1.45500381e+00 -1.31297673e+00]\n",
      " [-4.16009689e-01  1.03205722e+00 -1.39813811e+00 -1.31297673e+00]\n",
      " [-1.14301691e+00  1.06445364e-01 -1.28440670e+00 -1.44444970e+00]\n",
      " [-1.74885626e+00 -1.24957601e-01 -1.39813811e+00 -1.31297673e+00]\n",
      " [-9.00681170e-01  8.00654259e-01 -1.28440670e+00 -1.31297673e+00]\n",
      " [-1.02184904e+00  1.03205722e+00 -1.39813811e+00 -1.18150376e+00]\n",
      " [-1.62768839e+00 -1.74477836e+00 -1.39813811e+00 -1.18150376e+00]\n",
      " [-1.74885626e+00  3.37848329e-01 -1.39813811e+00 -1.31297673e+00]\n",
      " [-1.02184904e+00  1.03205722e+00 -1.22754100e+00 -7.87084847e-01]\n",
      " [-9.00681170e-01  1.72626612e+00 -1.05694388e+00 -1.05003079e+00]\n",
      " [-1.26418478e+00 -1.24957601e-01 -1.34127240e+00 -1.18150376e+00]\n",
      " [-9.00681170e-01  1.72626612e+00 -1.22754100e+00 -1.31297673e+00]\n",
      " [-1.50652052e+00  3.37848329e-01 -1.34127240e+00 -1.31297673e+00]\n",
      " [-6.58345429e-01  1.49486315e+00 -1.28440670e+00 -1.31297673e+00]\n",
      " [-1.02184904e+00  5.69251294e-01 -1.34127240e+00 -1.31297673e+00]\n",
      " [ 1.40150837e+00  3.37848329e-01  5.35295827e-01  2.64698913e-01]\n",
      " [ 6.74501145e-01  3.37848329e-01  4.21564419e-01  3.96171883e-01]\n",
      " [ 1.28034050e+00  1.06445364e-01  6.49027235e-01  3.96171883e-01]\n",
      " [-4.16009689e-01 -1.74477836e+00  1.37235899e-01  1.33225943e-01]\n",
      " [ 7.95669016e-01 -5.87763531e-01  4.78430123e-01  3.96171883e-01]\n",
      " [-1.73673948e-01 -5.87763531e-01  4.21564419e-01  1.33225943e-01]\n",
      " [ 5.53333275e-01  5.69251294e-01  5.35295827e-01  5.27644853e-01]\n",
      " [-1.14301691e+00 -1.51337539e+00 -2.60824029e-01 -2.61192967e-01]\n",
      " [ 9.16836886e-01 -3.56360566e-01  4.78430123e-01  1.33225943e-01]\n",
      " [-7.79513300e-01 -8.19166497e-01  8.03701950e-02  2.64698913e-01]\n",
      " [-1.02184904e+00 -2.43898725e+00 -1.47092621e-01 -2.61192967e-01]\n",
      " [ 6.86617933e-02 -1.24957601e-01  2.50967307e-01  3.96171883e-01]\n",
      " [ 1.89829664e-01 -1.97618132e+00  1.37235899e-01 -2.61192967e-01]\n",
      " [ 3.10997534e-01 -3.56360566e-01  5.35295827e-01  2.64698913e-01]\n",
      " [-2.94841818e-01 -3.56360566e-01 -9.02269170e-02  1.33225943e-01]\n",
      " [ 1.03800476e+00  1.06445364e-01  3.64698715e-01  2.64698913e-01]\n",
      " [-2.94841818e-01 -1.24957601e-01  4.21564419e-01  3.96171883e-01]\n",
      " [-5.25060772e-02 -8.19166497e-01  1.94101603e-01 -2.61192967e-01]\n",
      " [ 4.32165405e-01 -1.97618132e+00  4.21564419e-01  3.96171883e-01]\n",
      " [-2.94841818e-01 -1.28197243e+00  8.03701950e-02 -1.29719997e-01]\n",
      " [ 6.86617933e-02  3.37848329e-01  5.92161531e-01  7.90590793e-01]\n",
      " [ 3.10997534e-01 -5.87763531e-01  1.37235899e-01  1.33225943e-01]\n",
      " [ 5.53333275e-01 -1.28197243e+00  6.49027235e-01  3.96171883e-01]\n",
      " [ 3.10997534e-01 -5.87763531e-01  5.35295827e-01  1.75297293e-03]\n",
      " [ 6.74501145e-01 -3.56360566e-01  3.07833011e-01  1.33225943e-01]\n",
      " [ 9.16836886e-01 -1.24957601e-01  3.64698715e-01  2.64698913e-01]\n",
      " [ 1.15917263e+00 -5.87763531e-01  5.92161531e-01  2.64698913e-01]\n",
      " [ 1.03800476e+00 -1.24957601e-01  7.05892939e-01  6.59117823e-01]\n",
      " [ 1.89829664e-01 -3.56360566e-01  4.21564419e-01  3.96171883e-01]\n",
      " [-1.73673948e-01 -1.05056946e+00 -1.47092621e-01 -2.61192967e-01]\n",
      " [-4.16009689e-01 -1.51337539e+00  2.35044910e-02 -1.29719997e-01]\n",
      " [-4.16009689e-01 -1.51337539e+00 -3.33612130e-02 -2.61192967e-01]\n",
      " [-5.25060772e-02 -8.19166497e-01  8.03701950e-02  1.75297293e-03]\n",
      " [ 1.89829664e-01 -8.19166497e-01  7.62758643e-01  5.27644853e-01]\n",
      " [-5.37177559e-01 -1.24957601e-01  4.21564419e-01  3.96171883e-01]\n",
      " [ 1.89829664e-01  8.00654259e-01  4.21564419e-01  5.27644853e-01]\n",
      " [ 1.03800476e+00  1.06445364e-01  5.35295827e-01  3.96171883e-01]\n",
      " [ 5.53333275e-01 -1.74477836e+00  3.64698715e-01  1.33225943e-01]\n",
      " [-2.94841818e-01 -1.24957601e-01  1.94101603e-01  1.33225943e-01]\n",
      " [-4.16009689e-01 -1.28197243e+00  1.37235899e-01  1.33225943e-01]\n",
      " [-4.16009689e-01 -1.05056946e+00  3.64698715e-01  1.75297293e-03]\n",
      " [ 3.10997534e-01 -1.24957601e-01  4.78430123e-01  2.64698913e-01]\n",
      " [-5.25060772e-02 -1.05056946e+00  1.37235899e-01  1.75297293e-03]\n",
      " [-1.02184904e+00 -1.74477836e+00 -2.60824029e-01 -2.61192967e-01]\n",
      " [-2.94841818e-01 -8.19166497e-01  2.50967307e-01  1.33225943e-01]\n",
      " [-1.73673948e-01 -1.24957601e-01  2.50967307e-01  1.75297293e-03]\n",
      " [-1.73673948e-01 -3.56360566e-01  2.50967307e-01  1.33225943e-01]\n",
      " [ 4.32165405e-01 -3.56360566e-01  3.07833011e-01  1.33225943e-01]\n",
      " [-9.00681170e-01 -1.28197243e+00 -4.31421141e-01 -1.29719997e-01]\n",
      " [-1.73673948e-01 -5.87763531e-01  1.94101603e-01  1.33225943e-01]\n",
      " [ 5.53333275e-01  5.69251294e-01  1.27454998e+00  1.71090158e+00]\n",
      " [-5.25060772e-02 -8.19166497e-01  7.62758643e-01  9.22063763e-01]\n",
      " [ 1.52267624e+00 -1.24957601e-01  1.21768427e+00  1.18500970e+00]\n",
      " [ 5.53333275e-01 -3.56360566e-01  1.04708716e+00  7.90590793e-01]\n",
      " [ 7.95669016e-01 -1.24957601e-01  1.16081857e+00  1.31648267e+00]\n",
      " [ 2.12851559e+00 -1.24957601e-01  1.61574420e+00  1.18500970e+00]\n",
      " [-1.14301691e+00 -1.28197243e+00  4.21564419e-01  6.59117823e-01]\n",
      " [ 1.76501198e+00 -3.56360566e-01  1.44514709e+00  7.90590793e-01]\n",
      " [ 1.03800476e+00 -1.28197243e+00  1.16081857e+00  7.90590793e-01]\n",
      " [ 1.64384411e+00  1.26346019e+00  1.33141568e+00  1.71090158e+00]\n",
      " [ 7.95669016e-01  3.37848329e-01  7.62758643e-01  1.05353673e+00]\n",
      " [ 6.74501145e-01 -8.19166497e-01  8.76490051e-01  9.22063763e-01]\n",
      " [ 1.15917263e+00 -1.24957601e-01  9.90221459e-01  1.18500970e+00]\n",
      " [-1.73673948e-01 -1.28197243e+00  7.05892939e-01  1.05353673e+00]\n",
      " [-5.25060772e-02 -5.87763531e-01  7.62758643e-01  1.57942861e+00]\n",
      " [ 6.74501145e-01  3.37848329e-01  8.76490051e-01  1.44795564e+00]\n",
      " [ 7.95669016e-01 -1.24957601e-01  9.90221459e-01  7.90590793e-01]\n",
      " [ 2.24968346e+00  1.72626612e+00  1.67260991e+00  1.31648267e+00]\n",
      " [ 2.24968346e+00 -1.05056946e+00  1.78634131e+00  1.44795564e+00]\n",
      " [ 1.89829664e-01 -1.97618132e+00  7.05892939e-01  3.96171883e-01]\n",
      " [ 1.28034050e+00  3.37848329e-01  1.10395287e+00  1.44795564e+00]\n",
      " [-2.94841818e-01 -5.87763531e-01  6.49027235e-01  1.05353673e+00]\n",
      " [ 2.24968346e+00 -5.87763531e-01  1.67260991e+00  1.05353673e+00]\n",
      " [ 5.53333275e-01 -8.19166497e-01  6.49027235e-01  7.90590793e-01]\n",
      " [ 1.03800476e+00  5.69251294e-01  1.10395287e+00  1.18500970e+00]\n",
      " [ 1.64384411e+00  3.37848329e-01  1.27454998e+00  7.90590793e-01]\n",
      " [ 4.32165405e-01 -5.87763531e-01  5.92161531e-01  7.90590793e-01]\n",
      " [ 3.10997534e-01 -1.24957601e-01  6.49027235e-01  7.90590793e-01]\n",
      " [ 6.74501145e-01 -5.87763531e-01  1.04708716e+00  1.18500970e+00]\n",
      " [ 1.64384411e+00 -1.24957601e-01  1.16081857e+00  5.27644853e-01]\n",
      " [ 1.88617985e+00 -5.87763531e-01  1.33141568e+00  9.22063763e-01]\n",
      " [ 2.49201920e+00  1.72626612e+00  1.50201279e+00  1.05353673e+00]\n",
      " [ 6.74501145e-01 -5.87763531e-01  1.04708716e+00  1.31648267e+00]\n",
      " [ 5.53333275e-01 -5.87763531e-01  7.62758643e-01  3.96171883e-01]\n",
      " [ 3.10997534e-01 -1.05056946e+00  1.04708716e+00  2.64698913e-01]\n",
      " [ 2.24968346e+00 -1.24957601e-01  1.33141568e+00  1.44795564e+00]\n",
      " [ 5.53333275e-01  8.00654259e-01  1.04708716e+00  1.57942861e+00]\n",
      " [ 6.74501145e-01  1.06445364e-01  9.90221459e-01  7.90590793e-01]\n",
      " [ 1.89829664e-01 -1.24957601e-01  5.92161531e-01  7.90590793e-01]\n",
      " [ 1.28034050e+00  1.06445364e-01  9.33355755e-01  1.18500970e+00]\n",
      " [ 1.03800476e+00  1.06445364e-01  1.04708716e+00  1.57942861e+00]\n",
      " [ 1.28034050e+00  1.06445364e-01  7.62758643e-01  1.44795564e+00]\n",
      " [-5.25060772e-02 -8.19166497e-01  7.62758643e-01  9.22063763e-01]\n",
      " [ 1.15917263e+00  3.37848329e-01  1.21768427e+00  1.44795564e+00]\n",
      " [ 1.03800476e+00  5.69251294e-01  1.10395287e+00  1.71090158e+00]\n",
      " [ 1.03800476e+00 -1.24957601e-01  8.19624347e-01  1.44795564e+00]\n",
      " [ 5.53333275e-01 -1.28197243e+00  7.05892939e-01  9.22063763e-01]\n",
      " [ 7.95669016e-01 -1.24957601e-01  8.19624347e-01  1.05353673e+00]\n",
      " [ 4.32165405e-01  8.00654259e-01  9.33355755e-01  1.44795564e+00]\n",
      " [ 6.86617933e-02 -1.24957601e-01  7.62758643e-01  7.90590793e-01]]\n"
     ]
    }
   ],
   "source": [
    "# 스케일링은 자료 집합에 적용되는 전처리 과정으로 모든 자료에 선형 변환을 적용하여 전체 자료의 분포를 평균 0, 분산 1이 되도록 만드는 과정이다.스케일링은 자료의 오버플로우(overflow)나 언더플로우(underflow)를 방지하고 독립 변수의 공분산 행렬의 조건수(condition number)를 감소시켜 최적화 과정에서의 안정성 및 수렴 속도를 향상시킨다.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "X = standard_scaler.fit_transform(X)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split함수는 train,test로 데이터를 바꿔준다.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 32)                160       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 259\n",
      "Trainable params: 259\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 설계 코드\n",
    "# 케라스에서는 딥러닝 전체모델을 Sequential에 올리도록한다.\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "# Sequential클래스 할당\n",
    "model = Sequential()\n",
    "\n",
    "# 첫번째 계층 32개의 뉴런 입력 4개 활성화 함수는 시그모이드\n",
    "model.add(Dense(32, input_dim = 4, activation = 'sigmoid'))\n",
    "# 두번째 계층 출력 계층 3개의 뉴런, 입력 == 32 , 활성화 함수는 소프트맥스\n",
    "model.add(Dense(3, activation = 'softmax'))\n",
    "# 최적화 함수는 == adam , 손실함수는 categorical crossentropy, 평가척도  매트릭스를 할당하지 않을시 각 모델의 학습결과로 평가척도를 제공하지않음\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(Dense(32, input_dim = 4, activation = 'sigmoid'))\n",
    "# model.add(Dense(64, activation = 'sigmoid'))\n",
    "# model.add(Dense(128, activation = 'sigmoid'))\n",
    "# model.add(Dense(3, activation = 'softmax'))\n",
    "# model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 0s - loss: 1.1063 - acc: 0.2833\n",
      "Epoch 2/50\n",
      " - 0s - loss: 1.0966 - acc: 0.3000\n",
      "Epoch 3/50\n",
      " - 0s - loss: 1.0870 - acc: 0.3667\n",
      "Epoch 4/50\n",
      " - 0s - loss: 1.0777 - acc: 0.5167\n",
      "Epoch 5/50\n",
      " - 0s - loss: 1.0688 - acc: 0.5500\n",
      "Epoch 6/50\n",
      " - 0s - loss: 1.0597 - acc: 0.5917\n",
      "Epoch 7/50\n",
      " - 0s - loss: 1.0506 - acc: 0.6083\n",
      "Epoch 8/50\n",
      " - 0s - loss: 1.0419 - acc: 0.6250\n",
      "Epoch 9/50\n",
      " - 0s - loss: 1.0333 - acc: 0.6250\n",
      "Epoch 10/50\n",
      " - 0s - loss: 1.0244 - acc: 0.6333\n",
      "Epoch 11/50\n",
      " - 0s - loss: 1.0158 - acc: 0.6417\n",
      "Epoch 12/50\n",
      " - 0s - loss: 1.0078 - acc: 0.6500\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.9991 - acc: 0.6583\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.9907 - acc: 0.6583\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.9828 - acc: 0.6583\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.9745 - acc: 0.6750\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.9664 - acc: 0.6833\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.9585 - acc: 0.6833\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.9508 - acc: 0.6917\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.9429 - acc: 0.7000\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.9351 - acc: 0.7000\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.9275 - acc: 0.6917\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.9200 - acc: 0.6917\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.9122 - acc: 0.6917\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.9048 - acc: 0.6833\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.8973 - acc: 0.6833\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.8899 - acc: 0.6750\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.8827 - acc: 0.6750\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.8754 - acc: 0.6750\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.8685 - acc: 0.6750\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.8612 - acc: 0.6667\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.8542 - acc: 0.6667\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.8474 - acc: 0.6750\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.8404 - acc: 0.6750\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.8336 - acc: 0.6750\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.8267 - acc: 0.6750\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.8201 - acc: 0.6750\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.8135 - acc: 0.6750\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.8069 - acc: 0.6833\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.8002 - acc: 0.7000\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.7939 - acc: 0.7083\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.7874 - acc: 0.7167\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.7812 - acc: 0.7250\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.7747 - acc: 0.7333\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.7686 - acc: 0.7417\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.7625 - acc: 0.7417\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.7565 - acc: 0.7417\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.7505 - acc: 0.7667\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.7445 - acc: 0.7750\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.7385 - acc: 0.8083\n"
     ]
    }
   ],
   "source": [
    "# fit함수는 해달 모델로 학습을 시작하는 것 X축 데이터 == 속성, y축 데이터 == 클래스\n",
    "# 배치사이즈는 한번에 얼만큼의 학습량을 할지를 결정\n",
    "# 한번에 하나씩 학습한다면 효율 올라가지만 성능 내려감\n",
    "# epochs는 250개의 데이터를 얼마만큼 반복하냐 입니다. 50*250\n",
    "# verbose는 0은 조용히 1은 모양으로 2는 글자로\n",
    "hist=model.fit(X_train, y_train, batch_size = 64, epochs = 50, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "30/30 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7639164328575134, 0.800000011920929]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습된 모델을 테스트 데이터를 이용하여 검증\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 0s - loss: 0.7327 - acc: 0.8083\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.7270 - acc: 0.8250\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.7213 - acc: 0.8333\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.7158 - acc: 0.8250\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.7101 - acc: 0.8250\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.7045 - acc: 0.8333\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.6991 - acc: 0.8250\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.6939 - acc: 0.8333\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.6886 - acc: 0.8417\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.6833 - acc: 0.8500\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.6781 - acc: 0.8500\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.6729 - acc: 0.8500\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.6682 - acc: 0.8500\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.6630 - acc: 0.8500\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.6580 - acc: 0.8500\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.6534 - acc: 0.8500\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.6486 - acc: 0.8500\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.6438 - acc: 0.8583\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.6397 - acc: 0.8500\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.6347 - acc: 0.8667\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.6302 - acc: 0.8667\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.6260 - acc: 0.8667\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.6216 - acc: 0.8667\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.6172 - acc: 0.8667\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.6130 - acc: 0.8667\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.6089 - acc: 0.8667\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.6048 - acc: 0.8667\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.6007 - acc: 0.8667\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.5967 - acc: 0.8750\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.5929 - acc: 0.8750\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.5889 - acc: 0.8667\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.5851 - acc: 0.8667\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.5813 - acc: 0.8583\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.5777 - acc: 0.8667\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.5740 - acc: 0.8667\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.5703 - acc: 0.8667\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.5668 - acc: 0.8750\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.5633 - acc: 0.8667\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.5599 - acc: 0.8667\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.5564 - acc: 0.8667\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.5531 - acc: 0.8667\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.5497 - acc: 0.8750\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.5465 - acc: 0.8750\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.5433 - acc: 0.8750\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.5400 - acc: 0.8750\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.5369 - acc: 0.8750\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.5338 - acc: 0.8750\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.5308 - acc: 0.8750\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.5278 - acc: 0.8750\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.5248 - acc: 0.8750\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.5218 - acc: 0.8750\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.5190 - acc: 0.8750\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.5161 - acc: 0.8750\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.5133 - acc: 0.8750\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.5105 - acc: 0.8750\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.5079 - acc: 0.8750\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.5050 - acc: 0.8750\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.5023 - acc: 0.8750\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.4996 - acc: 0.8750\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.4971 - acc: 0.8750\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.4946 - acc: 0.8750\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.4920 - acc: 0.8750\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.4897 - acc: 0.8750\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.4870 - acc: 0.8750\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.4846 - acc: 0.8750\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.4821 - acc: 0.8750\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.4798 - acc: 0.8750\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.4774 - acc: 0.8750\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.4751 - acc: 0.8750\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.4728 - acc: 0.8750\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.4706 - acc: 0.8750\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.4682 - acc: 0.8750\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.4661 - acc: 0.8750\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.4640 - acc: 0.8750\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.4617 - acc: 0.8750\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.4595 - acc: 0.8750\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.4574 - acc: 0.8750\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.4552 - acc: 0.8750\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.4532 - acc: 0.8750\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.4512 - acc: 0.8750\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.4491 - acc: 0.8750\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.4471 - acc: 0.8750\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.4451 - acc: 0.8750\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.4432 - acc: 0.8750\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.4412 - acc: 0.8750\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.4393 - acc: 0.8750\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.4373 - acc: 0.8750\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.4355 - acc: 0.8750\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.4336 - acc: 0.8750\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.4318 - acc: 0.8750\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.4299 - acc: 0.8750\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.4280 - acc: 0.8750\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.4263 - acc: 0.8750\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.4245 - acc: 0.8833\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.4227 - acc: 0.8833\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.4209 - acc: 0.8833\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.4193 - acc: 0.8833\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.4177 - acc: 0.8833\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.4158 - acc: 0.8833\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.4141 - acc: 0.8833\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit(X_train, y_train, batch_size = 64, epochs = 100, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "30/30 [==============================] - 0s 48us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.426259845495224, 0.8999999761581421]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5. 학습과정 살펴보기\n",
    "# matplotlib는 그래프를 그리는 툴\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# subplots으로 plt차트 한묶음을 생성함\n",
    "# fig은 차트모양에 해당하고\n",
    "# loss_ax 는 손실 차트에 해당함\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "# loss_ax 와 x축을 공유하는 쌍 차트를 생성\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "# loss 차트의 데이터는 loss 색은 yellow 이름은 train loss\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "\n",
    "# ylim을 통해 차트의 최대 최소를 설정가능\n",
    "loss_ax.set_ylim([0.0, 0.5])\n",
    "\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "\n",
    "acc_ax.set_ylim([0.8, 1.0])\n",
    "\n",
    "# loss_ax와 acc_ax는 하나의 epoch축을 끼고 차트를 그림\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "# 범례를 설정하기 위한값\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
